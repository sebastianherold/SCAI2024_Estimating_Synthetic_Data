{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b188d49-010e-42ff-9103-2016ef3f0f4c",
   "metadata": {},
   "source": [
    "# Step 2: Preprocessing & Classification model\n",
    "This section will load up the defined settings from the pickles directory and run the machine learning pipeline with the help of the `pycaret` library and save respective data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all packages needed in this section\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys \n",
    "\n",
    "from sklearn.metrics import (classification_report,  \n",
    "                             matthews_corrcoef,\n",
    "                             cohen_kappa_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pycaret.classification import *\n",
    "from pycaret.containers.models.classification import get_all_model_containers\n",
    "\n",
    "# utility functions for the experiment\n",
    "sys.path.append('../src')\n",
    "\n",
    "from tuning_grids import Grids\n",
    "from utils import getPicklesFromDir, getExperimentConfig, run_pycaret_setup, translate_model_name\n",
    "# Get global experiment settings\n",
    "config = getExperimentConfig()\n",
    "folders = config['folders']\n",
    "# get a list of all settings for the datasets prepared beforehand\n",
    "dataset_settings = getPicklesFromDir(folders['settings_dir'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3938c0",
   "metadata": {},
   "source": [
    "dataset_settings pickle is saved as follows:\n",
    "```\n",
    "\"meta_data\": meta_dataset,  # contains information about the dataset, including path\n",
    "\"setup_param\": setup_param, # contains all the setup parameters for pycaret setup() function\n",
    "\"sdg_param\": sdg_param,     # contains all sdg parameters for the CTGAN() function\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc371f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv-file for model performance; if it exists, read it, else create a new one\n",
    "if os.path.isfile(folders['model_perf_filepath']):\n",
    "    model_performance_df = pd.read_csv(folders['model_perf_filepath'])\n",
    "else:\n",
    "    model_performance_df = pd.DataFrame()\n",
    "\n",
    "#dictionary to save model performance\n",
    "performance_row = {}\n",
    "\n",
    "run_dataset = config['run_dataset']\n",
    "\n",
    "for settings in dataset_settings:\n",
    "        \n",
    "    if run_dataset is not None and settings['meta']['id'] not in run_dataset:\n",
    "        # Checks if run_dataset contains dataset_id's\n",
    "        # if it does, run the experiment only on specified datasets\n",
    "        continue\n",
    "        \n",
    "    # get path\n",
    "    dataset_path = f\"{folders['real_dir']}{settings['meta']['filename']}\"\n",
    "    settings['setup_param']['fold'] = config['clf']['cv_folds']\n",
    "    # run setup function\n",
    "    s = run_pycaret_setup(dataset_path, settings['setup_param'], meta=settings['meta'])\n",
    "    \n",
    "    print(f\"Dataset: {settings['meta']['id']}-{settings['meta']['name']}\")\n",
    "    \n",
    "    logg_tags = {\n",
    "        'Dataset id': settings['meta']['id'],\n",
    "        'Tuned on': 'original',\n",
    "        'Trained on': 'original'\n",
    "    }\n",
    "    \n",
    "    # get the holdout data\n",
    "    y_test = s.get_config('y_test_transformed')\n",
    "    x_test_transformed = s.get_config('X_test_transformed')\n",
    "    s.test.to_csv(f\"{folders['real_dir']}{settings['meta']['id']}-{settings['meta']['name']}_test.csv\", index=False)\n",
    "    print(x_test_transformed.dtypes)\n",
    "    \n",
    "    # for each defined model in the global config\n",
    "    # create specified model and tune it\n",
    "    for ml_model in config['clf']['ml_models']:\n",
    "        \n",
    "        model_name = f\"{settings['meta']['id']}-{translate_model_name(ml_model)}\"\n",
    "        print(model_name)\n",
    "        \n",
    "        logg_tags['model']=ml_model\n",
    "\n",
    "        #all_models = get_all_model_containers(s)\n",
    "        #model = all_models[ml_model].class_def()\n",
    "        model = create_model(ml_model)\n",
    "\n",
    "        tune_grid = Grids.get_tuning_grid(ml_model)  \n",
    "        #print(f\"Tune grid: {tune_grid}\")\n",
    "        model = s.tune_model(model, custom_grid=tune_grid, **config['clf']['tuning_param'])\n",
    "\n",
    "        # get validation results\n",
    "        val_dict = s.pull().to_dict()\n",
    "               \n",
    "        y_pred = model.predict(x_test_transformed)\n",
    "        print(y_pred[:5])\n",
    "        print(y_test[:5])\n",
    "\n",
    "        metrics =  classification_report(y_true=y_test, y_pred=y_pred, output_dict=True, digits=4)\n",
    "        holdout_score = pd.DataFrame.from_dict(metrics).transpose()\n",
    "        \n",
    "        print(holdout_score)\n",
    "        test_metrics = {\n",
    "            \"Accuracy\": metrics['accuracy'],\n",
    "            \"Precision_macro\": metrics['macro avg']['precision'],\n",
    "            \"Recall_macro\": metrics['macro avg']['recall'],\n",
    "            \"F1_macro\": metrics['macro avg']['f1-score'],\n",
    "            \"Precision_weighted\": metrics['weighted avg']['precision'],\n",
    "            \"Recall_weighted\": metrics['weighted avg']['recall'],\n",
    "            \"F1_weighted\": metrics['weighted avg']['f1-score'],\n",
    "            \"MCC\": matthews_corrcoef(y_true=y_test, y_pred=y_pred),\n",
    "            \"Kappa\": cohen_kappa_score(y1=y_test, y2=y_pred),\n",
    "            \"sklearn-report\": metrics,\n",
    "            \"val_score\": val_dict\n",
    "        }\n",
    "        # save results\n",
    "        performance_row = {**logg_tags, **test_metrics}\n",
    "        performance_row['Params'] = tuned_model.get_params()\n",
    "        model_performance_df = model_performance_df.append(performance_row, ignore_index=True)\n",
    "    # Save model performance to csv\n",
    "    model_performance_df.to_csv(folders['model_perf_filepath'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0373980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%notify\n",
    "\n",
    "### Testing that the provided hyperparameters work with pycaret and the system\n",
    "#settings = dataset_settings[0]\n",
    "#dataset_path = f\"{folders['real_dir']}{settings['meta']['filename']}\"\n",
    "#s = run_pycaret_setup(dataset_path, settings['setup_param'])\n",
    "#for ml_model in ['rf', 'gbc', 'mlp']: #config['clf']['ml_models']:\n",
    "#    # create & tune model\n",
    "#    #model = s.create_model(ml_model)\n",
    "#    #Quickfix for efficiency\n",
    "#    all_models = get_all_model_containers(s)\n",
    "#    model = all_models[ml_model].class_def()\n",
    "\n",
    "#    tune_grid = Grids.get_tuning_grid(ml_model)\n",
    "#    tuned_model = s.tune_model(model, \n",
    "#                               **config['clf']['tuning_param'], \n",
    "#                               custom_grid=tune_grid\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#type_of_target(y_df)\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#label_encoder = LabelEncoder()\n",
    "#y = label_encoder.fit_transform(y_df)\n",
    "\n",
    "#display(type(y))\n",
    "#display(type_of_target(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "163px",
    "width": "322px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
